{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac64bf6",
   "metadata": {},
   "source": [
    "# Análisis y Procesamiento de Imágenes\n",
    "Este notebook implementa un flujo de trabajo completo para el análisis de imágenes, limpieza, preprocesamiento, extracción de características y despliegue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb56e2",
   "metadata": {},
   "source": [
    "### 1. Análisis Exploratorio (Similitudes y Diferencias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d18b5",
   "metadata": {},
   "source": [
    "### Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install scikit-image\n",
    "!pip install flask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97899953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ruta al directorio de imágenes\n",
    "image_folder = 'circuits/'\n",
    "\n",
    "# Obtener una lista de archivos de imagen válidos en el directorio\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# Cargar imágenes\n",
    "images = [cv2.imread(img_path) for img_path in image_files]\n",
    "\n",
    "# Verificar que todas las imágenes se cargaron correctamente\n",
    "for i, (img, img_path) in enumerate(zip(images, image_files)):\n",
    "    if img is None:\n",
    "        print(f'Error: No se pudo cargar la imagen {img_path}.')\n",
    "    else:\n",
    "        print(f'Imagen {i+1} ({img_path}) cargada correctamente.')\n",
    "\n",
    "# Mostrar imágenes en una cuadrícula\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, img in enumerate(images):\n",
    "    if img is not None:  # Verificar si la imagen es válida antes de mostrarla\n",
    "        plt.subplot(4, 5, i+1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "plt.suptitle('Visualización de Imágenes', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff88af",
   "metadata": {},
   "source": [
    "### Histogramas de Colores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(images):\n",
    "    plt.figure()\n",
    "    plt.hist(img.ravel(), bins=256, color='orange', label='Intensity')\n",
    "    plt.hist(img[:, :, 0].ravel(), bins=256, color='blue', alpha=0.5, label='Blue Channel')\n",
    "    plt.hist(img[:, :, 1].ravel(), bins=256, color='green', alpha=0.5, label='Green Channel')\n",
    "    plt.hist(img[:, :, 2].ravel(), bins=256, color='red', alpha=0.5, label='Red Channel')\n",
    "    plt.title(f'Color Histogram - Image {i+1}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf17ce",
   "metadata": {},
   "source": [
    "## 2. Técnicas de Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar imágenes corruptas\n",
    "for i, img in enumerate(images):\n",
    "    if img is None:\n",
    "        print(f'La imagen {i+1} está corrupta o no se pudo abrir.')\n",
    "\n",
    "# Detectar duplicados usando SSIM\n",
    "def are_images_similar(img1, img2):\n",
    "    if img1.shape != img2.shape:\n",
    "        return False\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    score, _ = ssim(gray1, gray2, full=True)\n",
    "    return score > 0.95\n",
    "\n",
    "duplicates = []\n",
    "for i in range(len(images)):\n",
    "    for j in range(i + 1, len(images)):\n",
    "        if are_images_similar(images[i], images[j]):\n",
    "            duplicates.append((i, j))\n",
    "print(f'Pares de imágenes duplicadas: {duplicates}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386bf43a",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento y Aumento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf2f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionar y normalizar las imágenes\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir el tamaño objetivo para redimensionar las imágenes (224x224)\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Redimensionar todas las imágenes al tamaño objetivo\n",
    "resized_images = [cv2.resize(img, target_size) for img in images]\n",
    "\n",
    "# Normalizar las imágenes dividiendo entre 255.0 para tener valores en el rango [0, 1]\n",
    "normalized_images = [img / 255.0 for img in resized_images]\n",
    "\n",
    "# Aumento de datos: aplicar transformaciones aleatorias a las imágenes para crear variaciones\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Rotación aleatoria de las imágenes en un rango de 20 grados\n",
    "    width_shift_range=0.2,  # Desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.2,  # Desplazamiento vertical aleatorio\n",
    "    shear_range=0.2,  # Aplicar cizallamiento aleatorio\n",
    "    zoom_range=0.2,  # Zoom aleatorio en las imágenes\n",
    "    horizontal_flip=True,  # Voltear las imágenes horizontalmente de forma aleatoria\n",
    "    fill_mode='nearest'  # Rellenar los píxeles vacíos con los valores más cercanos\n",
    ")\n",
    "\n",
    "# Crear un conjunto de imágenes aumentadas\n",
    "augmented_images = []\n",
    "for img in normalized_images:\n",
    "    img = np.expand_dims(img, axis=0)  # Expandir dimensiones para que sea compatible con el generador\n",
    "    aug_iter = datagen.flow(img, batch_size=1)  # Crear un iterador para generar imágenes aumentadas\n",
    "    augmented_images.extend([next(aug_iter)[0] for _ in range(5)])  # Generar 5 imágenes aumentadas por cada imagen original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50160282",
   "metadata": {},
   "source": [
    "## 4. Extracción de Características y Detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2054f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Feature extraction using VGG16\n",
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "features = [model.predict(preprocess_input(np.expand_dims(img, axis=0))) for img in normalized_images]\n",
    "\n",
    "# Texture analysis using Sobel filter\n",
    "for i, img in enumerate(images):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    plt.figure()\n",
    "    plt.imshow(sobelx, cmap='gray')\n",
    "    plt.title(f'Sobel X Filter - Image {i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ea9f9",
   "metadata": {},
   "source": [
    "## 5. Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce26e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el MSE (Error Cuadrático Medio) entre imágenes normalizadas\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "# Calcular MSE entre las imágenes normalizadas\n",
    "for i in range(len(normalized_images)):\n",
    "    for j in range(i + 1, len(normalized_images)):\n",
    "        mse_value = mse(normalized_images[i], normalized_images[j])\n",
    "        print(f'MSE entre la imagen {i+1} y la imagen {j+1}: {mse_value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b682de3",
   "metadata": {},
   "source": [
    "## 6. Despliegue o endpoint para añadir más imágenes al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d471b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la aplicación Flask\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Ruta donde se guardarán las imágenes\n",
    "UPLOAD_FOLDER = 'circuits'\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "# Cargar el modelo VGG16 (o el que estés usando)\n",
    "model = VGG16(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ed625",
   "metadata": {},
   "source": [
    "### Definición de la ruta /predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47285be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    file = request.files['image']\n",
    "    \n",
    "    # Guardar la imagen en el directorio /circuits\n",
    "    image_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "    file.save(image_path)\n",
    "    \n",
    "    # Procesar la imagen\n",
    "    image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (224, 224))  # Redimensionar a 224x224, tamaño esperado por VGG16\n",
    "    image = np.expand_dims(image, axis=0)  # Expande las dimensiones de la imagen para que tenga forma (1, 224, 224, 3)\n",
    "    image = preprocess_input(image)  # Preprocesamiento específico para VGG16\n",
    "    \n",
    "    # Realizar predicción\n",
    "    preds = model.predict(image)\n",
    "    \n",
    "    # Retornar los resultados como JSON\n",
    "    return jsonify(preds.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def run_flask():\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "\n",
    "# Ejecutar Flask en un hilo separado\n",
    "thread = Thread(target=run_flask)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afd8b3f",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "Este cuaderno demuestra un flujo de trabajo completo para el análisis de imágenes, desde la exploración hasta el despliegue en pro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
